<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://luyao787.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://luyao787.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-05-28T00:27:59+02:00</updated><id>https://luyao787.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">linear quadratic problem</title><link href="https://luyao787.github.io/blog/2025/LQP/" rel="alternate" type="text/html" title="linear quadratic problem"/><published>2025-05-25T00:00:00+02:00</published><updated>2025-05-25T00:00:00+02:00</updated><id>https://luyao787.github.io/blog/2025/LQP</id><content type="html" xml:base="https://luyao787.github.io/blog/2025/LQP/"><![CDATA[<p>In this blog, we introduce the recursive method for solving the following LQR problem \(\begin{aligned} \min_{\bar{x}, \bar{u}} \quad &amp;\sum_{k=0}^{N-1} \begin{bmatrix} q_k \\ r_k \end{bmatrix}^\top \begin{bmatrix} x_k \\ u_k \end{bmatrix} + \frac{1}{2} \begin{bmatrix} x_k \\ u_k \end{bmatrix}^\top \begin{bmatrix} Q_k &amp; S_k^\top \\ S_k &amp; R_k \end{bmatrix} \begin{bmatrix} x_k \\ u_k \end{bmatrix} \\ &amp;\quad\quad + p_N^\top x_N + \frac{1}{2} x_N^T P_N x_N \\ \text{s.t.}\quad &amp; x_{k+1} = A_k x_k + B_k u_k + c_k,\; k = 0, \dots, N-1, \end{aligned}\) where $\bar{x} := { x_1, \dots, x_N }$ and $\bar{u} := { u_0, \dots, u_{N-1} }$. We consider the LQR problem as a quadratic program with equality constraints. The corresponding Lagrangian is then expresed as $$ \begin{aligned} \mathcal{L} (\bar{x}, \bar{u}, \bar{\lambda}) &amp;= \sum_{k=0}^{N-1} \Bigg( \begin{bmatrix} q_k \ r_k \end{bmatrix}^\top \begin{bmatrix} x_k \ u_k \end{bmatrix}</p> <ul> <li>\frac{1}{2} \begin{bmatrix} x_k \ u_k \end{bmatrix}^\top \begin{bmatrix} Q_k &amp; S_k^\top \ S_k &amp; R_k \end{bmatrix} \begin{bmatrix} x_k \ u_k \end{bmatrix}</li> <li>\lambda_{k+1}^\top \left(A_k x_k + B_k u_k + c_k - x_{k+1} \right) \Bigg) <br/> &amp;\quad\quad\quad + p_N^\top x_N + \frac{1}{2} x_N^T P_N x_N, \end{aligned} \(where $\bar{\lambda} = (\lambda_1, \cdots, \lambda_N)$ is a vector of Lagrange multipliers. The KKT conditions are derived as\) \begin{aligned} \frac{\partial \mathcal{L}}{\partial \bar{x}} = 0,\; \frac{\partial \mathcal{L}}{\partial \bar{u}} = 0,\; \frac{\partial \mathcal{L}}{\partial \bar{\lambda}} = 0. \end{aligned} $$</li> </ul> <p>For $k = 0$, \(\begin{aligned} 0 &amp;= r_0 + R_0 u_0 + S_0 x_0 + B_0^\top \lambda_{1}. \end{aligned}\)</p> <p>For $0 &lt; k &lt;= N-1$, \(\begin{aligned} 0 &amp;= q_k + Q_k x_k + S_k^\top u_k + A_k^\top \lambda_{k+1} - \lambda_k , \\ 0 &amp;= r_k + R_k u_k + S_k x_k + B_k^\top \lambda_{k+1}, \\ 0 &amp;= A_{k-1} x_{k-1} + B_{k-1} u_{k-1} + c_{k-1} - x_k. \end{aligned}\)</p> <p>For $k = N$, \(\begin{aligned} 0 &amp;= p_N + P_N x_N - \lambda_N , \\ 0 &amp;= A_{N-1} x_{N-1} + B_{N-1} u_{N-1} + c_{N-1} - x_N. \end{aligned}\)</p> <p>The corresponding KKT system $(N = 3)$ is then \(\begin{equation*} \left[ \begin{array}{ccccccccc} R_0 &amp; B_0^\top \\ B_0 &amp; &amp; -I\\ \hline &amp; -I &amp; Q_1 &amp; S_1^\top &amp; A_1^\top \\ &amp; &amp; S_1 &amp; R_1 &amp; B_1^\top \\ &amp; &amp; A_1 &amp; B_1 &amp; &amp; -I \\ \hline &amp; &amp; &amp; &amp; -I &amp; Q_2 &amp; S_2^\top &amp; A_2^\top \\ &amp; &amp; &amp; &amp; &amp; S_2 &amp; R_2 &amp; B_2^\top \\ &amp; &amp; &amp; &amp; &amp; A_2 &amp; B_2 &amp; &amp; -I \\ \hline &amp; &amp; &amp; &amp; &amp; &amp; &amp; -I &amp; P_3 \end{array} \right] \left[ \begin{array}{c} u_0 \\ \lambda_1 \\ \hline x_1 \\ u_1 \\ \lambda_2 \\ \hline x_2 \\ u_2 \\ \lambda_3 \\ \hline x_3 \end{array} \right] = \left[ \begin{array}{c} -r_0 - S_0 x_0 \\ -A x_0 - c_0 \\ \hline -q_1 \\ -r_1 \\ -c_1 \\ \hline -q_2 \\ -r_2 \\ -c_2 \\ \hline -p_3 \end{array} \right] \end{equation*}.\)</p> <p>Next, we recursively factorize the KKT matrix, starting from the last two stages: \(\begin{equation*} \left[ \begin{array}{ccccccccc} -I &amp; Q_{N-1} &amp; S_{N-1}^\top &amp; A_{N-1}^\top \\ &amp; S_{N-1} &amp; R_{N-1} &amp; B_{N-1}^\top \\ &amp; A_{N-1} &amp; B_{N-1} &amp; &amp; -I \\ \hline &amp; &amp; &amp; -I &amp; P_N \end{array} \right] \left[ \begin{array}{c} \lambda_{N-1} \\ \hline x_{N-1} \\ u_{N-1} \\ \lambda_{N} \\ \hline x_N \end{array} \right] = \left[ \begin{array}{c} -q_{N-1} \\ -r_{N-1} \\ -c_{N-1} \\ \hline -p_N \end{array} \right] \end{equation*}.\)</p> <p>By adding the 4th row to the 3rd row multiplied by $P_N$, we can eliminate the 4th row and obtain \(\begin{equation*} \left[ \begin{array}{ccccccccc} -I &amp; Q_{N-1} &amp; S_{N-1}^\top &amp; A_{N-1}^\top \\ &amp; S_{N-1} &amp; R_{N-1} &amp; B_{N-1}^\top \\ &amp; P_N A_{N-1} &amp; P_N B_{N-1} &amp; -I \end{array} \right] \left[ \begin{array}{c} \lambda_{N-1} \\ \hline x_{N-1} \\ u_{N-1} \\ \lambda_{N} \end{array} \right] = \left[ \begin{array}{c} -q_{N-1} \\ -r_{N-1} \\ -P_N c_{N-1} - p_N \end{array} \right] \end{equation*}.\)</p> <p>To eliminate the 3rd row, we add it multiplied by $\textcolor{red}{A_{N-1}^\top}$ to the 1st row and add it multiplied by $\textcolor{blue}{B_{N-1}^\top}$ to the 2nd row, resulting in \(\begin{equation*} \left[ \begin{array}{ccccccccc} -I &amp; Q_{N-1} + \textcolor{red}{A_{N-1}^\top} P_N A_{N-1} &amp; S_{N-1}^\top + \textcolor{red}{A_{N-1}^\top} P_N B_{N-1} \\ &amp; S_{N-1} + \textcolor{blue}{B_{N-1}^\top} P_N A_{N-1} &amp; R_{N-1} + \textcolor{blue}{B_{N-1}^\top} P_N B_{N-1} \\ \end{array} \right] \left[ \begin{array}{c} \lambda_{N-1} \\ \hline x_{N-1} \\ u_{N-1} \end{array} \right] = \left[ \begin{array}{c} -q_{N-1} - A_{N-1}^\top (P_N c_{N-1} + p_N) \\ -r_{N-1} - B_{N-1}^\top (P_N c_{N-1} + p_N) \end{array} \right] \end{equation*}.\)</p> <p>For notational simplicity, we use \(\begin{aligned} Q_{xx,k} &amp;= Q_{k} + A_k^\top P_{k+1}A_k\\ Q_{uu,k} &amp;= R_{k} + B_k^\top P_{k+1}B_k\\ Q_{ux,k} &amp;= S_{k} + B_k^\top P_{k+1}A_k \\ Q_{x,k} &amp;= q_k + A_k^\top \left( P_{k+1} c_k + p_{k+1} \right)\\ Q_{u,k} &amp;= r_k + B_k^\top \left( P_{k+1} c_k + p_{k+1} \right). \end{aligned}\)</p> <p>We then represent $u_{N-1}$ in terms of $x_{N-1}$ \(\begin{aligned} Q_{ux, N-1} x_{N-1} + Q_{uu, N-1} u_{N-1} &amp;= - Q_{u, N-1} \\ u_{N-1} &amp;= - Q_{uu, N-1}^{-1} Q_{ux, N-1} x_{N-1} - Q_{uu, N-1}^{-1} Q_{u, N-1} \\ &amp;:= K_{N-1} x_{N-1} + d_{N-1}. \end{aligned}\) We also have \(\begin{aligned} -\lambda_{N-1} + Q_{xx, N-1} x_{N-1} + Q_{ux, N-1}^\top u_{N-1} &amp;= - Q_{x, N-1} \\ -\lambda_{N-1} + Q_{xx, N-1} x_{N-1} + Q_{ux, N-1}^\top (-Q_{uu, N-1}^{-1} Q_{ux, N-1} x_{N-1} - Q_{uu, N-1}^{-1} Q_{u, N-1}) &amp;= -Q_{x, N-1} \end{aligned}\)</p> \[\begin{aligned} \lambda_{N-1} &amp;= \left( Q_{xx, N-1} - Q_{ux, N-1}^\top Q_{uu, N-1}^{-1} Q_{ux, N-1} \right) x_{N-1} + Q_{x, N-1} - Q_{ux, N-1}^\top Q_{uu, N-1}^{-1} Q_{u, N-1} \\ &amp;:= P_{N-1} x_{N-1} + p_{N-1}. \end{aligned}\] <p>This indicates the relation between $\lambda_k$ and $x_k$, and it is not difficult to derive the submatrix to be factorized at stage $k$ \(\begin{equation*} \left[ \begin{array}{ccccccccc} -I &amp; Q_{k} &amp; S_{k}^\top &amp; A_{k}^\top \\ &amp; S_{k} &amp; R_{k} &amp; B_{k}^\top \\ &amp; A_{k} &amp; B_{k} &amp; &amp; -I \\ \hline &amp; &amp; &amp; -I &amp; P_{k+1} \end{array} \right] \left[ \begin{array}{c} \lambda_{k} \\ \hline x_{k} \\ u_{k} \\ \lambda_{k+1} \\ \hline x_{k+1} \end{array} \right] = \left[ \begin{array}{c} -q_{k} \\ -r_{k} \\ -c_{k} \\ \hline -p_{k+1} \end{array} \right] \end{equation*}.\) We can repeat the same procedure as above to factorize this submatrix until the initial stage. After the <strong>factorization phase</strong>, we use the computed matrices $K_k$ and $d_k$ to recover the optimal state and input trajectories. This is called the <strong>solution phase</strong>. The descriptions of the two algorithms are shown below.</p> <p align="center"> <img src="../assets/img/LQP/LQR_fact.png"/> </p> <p align="center"> <img src="../assets/img/LQP/LQR_sol.png"/> </p> <p>Note that Line 11 in Algorithm 1 can improve the numerical stability. The methods $\texttt{choFact}$ and $\texttt{choSolve}$ compute the Cholesky decomposition and solve the linear system using the Cholesky factorization, respectively.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[In this blog, we introduce the recursive method for solving the following LQR problem \(\begin{aligned} \min_{\bar{x}, \bar{u}} \quad &amp;\sum_{k=0}^{N-1} \begin{bmatrix} q_k \\ r_k \end{bmatrix}^\top \begin{bmatrix} x_k \\ u_k \end{bmatrix} + \frac{1}{2} \begin{bmatrix} x_k \\ u_k \end{bmatrix}^\top \begin{bmatrix} Q_k &amp; S_k^\top \\ S_k &amp; R_k \end{bmatrix} \begin{bmatrix} x_k \\ u_k \end{bmatrix} \\ &amp;\quad\quad + p_N^\top x_N + \frac{1}{2} x_N^T P_N x_N \\ \text{s.t.}\quad &amp; x_{k+1} = A_k x_k + B_k u_k + c_k,\; k=0, \dots, N-1, \end{aligned}\) where $\bar{x} := { x_1, \dots, x_N }$ and $\bar{u} := { u_0, \dots, u_{N-1} }$. We consider the LQR problem as a quadratic program with equality constraints. The corresponding Lagrangian is then expresed as $$ \begin{aligned} \mathcal{L} (\bar{x}, \bar{u}, \bar{\lambda}) &amp;= \sum_{k=0}^{N-1} \Bigg( \begin{bmatrix} q_k \ r_k \end{bmatrix}^\top \begin{bmatrix} x_k \ u_k \end{bmatrix} \frac{1}{2} \begin{bmatrix} x_k \ u_k \end{bmatrix}^\top \begin{bmatrix} Q_k &amp; S_k^\top \ S_k &amp; R_k \end{bmatrix} \begin{bmatrix} x_k \ u_k \end{bmatrix} \lambda_{k+1}^\top \left(A_k x_k + B_k u_k + c_k - x_{k+1} \right) \Bigg) &amp;\quad\quad\quad + p_N^\top x_N + \frac{1}{2} x_N^T P_N x_N, \end{aligned} \(where $\bar{\lambda} = (\lambda_1, \cdots, \lambda_N)$ is a vector of Lagrange multipliers. The KKT conditions are derived as\) \begin{aligned} \frac{\partial \mathcal{L}}{\partial \bar{x}} = 0,\; \frac{\partial \mathcal{L}}{\partial \bar{u}} = 0,\; \frac{\partial \mathcal{L}}{\partial \bar{\lambda}} = 0. \end{aligned} $$]]></summary></entry></feed>